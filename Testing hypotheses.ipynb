{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing hypothesis\n",
    "\n",
    "Within this Jupyter notebook, we will finally use the test set. We will evaluate the classifier accuracies for the different classifiers we constructed. This will allow us to evaluate our hypotheses. First, let us load the packages and necessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import gc\n",
    "from functools import reduce\n",
    "from nltk import FreqDist, ngrams, sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training and test data...\n"
     ]
    }
   ],
   "source": [
    "# Load the training data. Scramble the rows (sometimes this is important for training)\n",
    "df = pd.read_csv(\"python_data/train\",sep=\"\\t\",error_bad_lines=False,encoding=\"utf-8\")\n",
    "df = df.sample(frac=1, random_state = 54021)\n",
    "df['native'] = np.where(df['native_lang']=='EN', \"native\", \"non-native\")\n",
    "\n",
    "# Load the training data. Downsample non-English such that it is balanced.\n",
    "print(\"Loading the training and test data...\")\n",
    "training = pd.concat([df[df.native == \"non-native\"].sample(sum(df.native == \"native\"), random_state = 1810), df[df.native==\"native\"]])\n",
    "training = training.sample(frac=1, random_state = 1318910)\n",
    "training.native = training.native.astype('category')\n",
    "\n",
    "# Load the test data. Again, downsample such that it is balanced.\n",
    "test = pd.read_csv(\"python_data/test\",sep=\"\\t\",error_bad_lines=False,encoding=\"utf-8\")\n",
    "test['native'] = np.where(test['native_lang']=='EN', \"native\", \"non-native\")\n",
    "test = pd.concat([test[test.native == \"non-native\"].sample(sum(test.native == \"native\"), random_state = 1), test[test.native==\"native\"]])\n",
    "test.native = test.native.astype('category')\n",
    "\n",
    "training.to_csv(\"python_data/training_final\")\n",
    "test.to_csv(\"python_data/test_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The non-linear kernel vs. the linear SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_similarity_score(dis_ngramdic, gramlist):\n",
    "    \"\"\" This function computes the similarity scores for a comment based on the corresponding k-grams.\n",
    "    Note that the comment is already tokenized into sentences.\n",
    "    @dis_ngramdic: ngram dictionary as constructed by language_distribution for particular k.\n",
    "    @gramlist: list of kgrams\n",
    "    \"\"\"\n",
    "    score=0\n",
    "    if gramlist:\n",
    "        for gram in gramlist:\n",
    "            score += math.log2(dis_ngramdic.get(gram,1))\n",
    "    return score\n",
    "\n",
    "colnames = None\n",
    "\n",
    "def compute_all_features(lang_dis, original_text, clean_text, structure_text):\n",
    "    \"\"\" This function compares the sentences and structure to each of the languages distributions. It returns\n",
    "    similarity scores to each language model. Also included are other features, such as the number of sentences\n",
    "    per text, etc.\n",
    "    @lang_dis: Language distribution of n-grams.\n",
    "    @clean_text: Text with proper nouns and demonyms substituted\n",
    "    @structure_text: PoS structure retrieved by SENNA.\n",
    "    \"\"\"\n",
    "    simscoredict=dict()\n",
    "    \n",
    "    # For each gramtype, first construct the list of which we can make n-grams.\n",
    "    words_ps = list(word_tokenize(clean_text))\n",
    "    struc_ps = list(word_tokenize(structure_text))\n",
    "    wordlens_ps = [len(word) for word in word_tokenize(original_text) if word.isalpha()]\n",
    "    \n",
    "    # Now we should construct k-gram lists for each k and return the score. Let us store all grams in \n",
    "    for gramtype in lang_dis[list(lang_dis.keys())[0]].keys():\n",
    "        \n",
    "        # Select appropriate data type.\n",
    "        if gramtype == \"tags\":\n",
    "            ps = struc_ps\n",
    "        elif gramtype ==\"words\":\n",
    "            ps = words_ps\n",
    "        elif gramtype == \"w_sizes\":\n",
    "            ps = wordlens_ps\n",
    "        elif gramtype == \"chars\":\n",
    "            ps = clean_text\n",
    "        \n",
    "        # We need to normalize with the sequence length.\n",
    "        seq_len = len(ps)\n",
    "\n",
    "        # For each k, feed the ngrams function into the compute_similarity_score function. \n",
    "        for k in range(1,len(lang_dis[list(lang_dis.keys())[0]][gramtype])+1):\n",
    "            for lang in lang_dis.keys():\n",
    "                simscoredict[lang+'_'+gramtype+'_'+str(k)]= compute_similarity_score(lang_dis[lang][gramtype][k], ngrams(ps,k))/seq_len\n",
    "    \n",
    "    # Set the other features they use in the paper.\n",
    "    simscoredict[\"num_sentences\"] = len(list(sent_tokenize(clean_text)))\n",
    "    simscoredict[\"num_words\"] = len(wordlens_ps)\n",
    "    simscoredict[\"avg_wordlength\"] = sum(wordlens_ps)/len(wordlens_ps)\n",
    "        \n",
    "    global colnames\n",
    "    if colnames == None:\n",
    "        colnames = list(simscoredict.keys())\n",
    "            \n",
    "    return simscoredict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the features for test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing features\n"
     ]
    }
   ],
   "source": [
    "# Load the language distribution for the training data.\n",
    "test = pd.read_csv(\"python_data/test_final\")\n",
    "lang_dis = load_object(\"trained_lang_dis\")\n",
    "lowerlim = 10\n",
    "\n",
    "print(\"Computing the features for test data\")\n",
    "features = test.apply(lambda row: compute_all_features(lang_dis,row['text_original'],row['text_clean'], row['text_structure']), axis=1)\n",
    "features = pd.DataFrame(features.to_frame()[0].values.tolist(), index=features.to_frame()[0].index, columns=colnames)\n",
    "test = pd.merge(test, features, left_index=True, right_index=True)\n",
    "print(\"Finished computing features\")\n",
    "\n",
    "# Clean up stuff we no longer need.\n",
    "lang_dis.clear()\n",
    "features = features.iloc[0:0]\n",
    "test = test.drop(['text_original','text_clean','text_structure'], axis = 1)\n",
    "\n",
    "# Write the training and test including their features to file.\n",
    "test.to_csv(\"python_data/test_features_4_4_\"+str(lowerlim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our features, we get to the classifier. Let us train the linear SVM classifier for default settings and with the non-linear kernel using Bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the feature set.\n",
    "training = pd.read_csv(\"python_data/training_features_4_4_10\",index_col=0,header=0)\n",
    "test = pd.read_csv(\"python_data/test_features_4_4_10\",index_col = 0, header=0)\n",
    "colnames = training.columns[3:]    #First column native language, second English level, third if native.\n",
    "test.native = test.native.astype('category')\n",
    "training.native = training.native.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.7196239381502338\n"
     ]
    }
   ],
   "source": [
    "# Train the SVC classifier\n",
    "linear = svm.LinearSVC(C=1, penalty=\"l1\", dual=False)\n",
    "linear.fit(training[colnames], training.native)\n",
    "y_predicted = linear.predict(test[colnames])\n",
    "accur = accuracy_score(test.native, y_predicted)\n",
    "print(\"Accuracy on the test set: {}\".format(accur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier\n",
      "Prediction out-of-sample\n",
      "Bagging SVC score: 0.738808819319\n"
     ]
    }
   ],
   "source": [
    "# Scaling.\n",
    "scaler = StandardScaler()\n",
    "training[colnames] = scaler.fit_transform(training[colnames])\n",
    "test_wordcounts = test.num_words\n",
    "test[colnames] = scaler.transform(test[colnames])\n",
    "\n",
    "# Train SVCs by bagging. 20 estimators will yield approximately 10.000 samples per SVM. This number should be feasible\n",
    "# according to the documentation. We can speed up things by multithreading (n_jobs).\n",
    "n_estimators = 20\n",
    "clf = BaggingClassifier(svm.SVC(kernel='rbf', C=2**3, gamma=2**-11, cache_size=2000), random_state = 1281, max_samples=1.0 / n_estimators, n_jobs = 4, n_estimators=n_estimators)\n",
    "print(\"Fitting the classifier\")\n",
    "clf.fit(training[colnames],training.native)\n",
    "print(\"Prediction out-of-sample\")\n",
    "y_predicted = clf.predict(test[colnames])\n",
    "print(\"Bagging SVC score:\",accuracy_score(test.native, y_predicted))\n",
    "\n",
    "# Save predictions.\n",
    "y_predicted = pd.DataFrame(y_predicted, test.index)\n",
    "y_predicted.columns = [\"prediction\"]\n",
    "dfs = [test[[\"native_lang\",\"level_english\",\"native\"]], y_predicted, pd.DataFrame(test_wordcounts, test.index)]\n",
    "y_predicted = reduce(lambda left,right: pd.merge(left,right, left_index= True, right_index = True), dfs)\n",
    "y_predicted.to_csv(\"output_SVM_RBF_classifier_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying based on the different distributions.\n",
    "\n",
    "Here, we evaluate accuracy on test data based on DTM. First, prepare features for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_lodds_ratio_dict(fname, lb):\n",
    "    \"\"\" \n",
    "    In this function, we want to compute the odds ratio for each of the n-grams, and return a dictionary with these values.\n",
    "    For each non-English language, we will add a pseudocount of .5 to prevent divisions by 0. We return an approximate lower\n",
    "    bound at the alpha confidence level.\n",
    "    @fname: File to load the language distribution from\n",
    "    @alpha: level of alpha of lower bound. \n",
    "    \"\"\"\n",
    "    \n",
    "    lang_dis = load_object(fname)\n",
    "    \n",
    "    n = len(lang_dis['EN']['words'])\n",
    "    m = len(lang_dis['EN']['chars'])\n",
    "    \n",
    "    for lang in lang_dis.keys():\n",
    "        if lang == 'EN':\n",
    "            continue\n",
    "        for gramtype in lang_dis[lang].keys():  \n",
    "            for k in lang_dis[lang][gramtype].keys():\n",
    "                b = sum(lang_dis[lang][gramtype][k].values()) + .5   #Total grams in foreign language\n",
    "                d = sum(lang_dis['EN'][gramtype][k].values()) + .5   #Total grams in English\n",
    "                for key in list(lang_dis[lang][gramtype][k].keys()):\n",
    "                    \n",
    "                    # Obtain the value by pop, i.e. delete key from dictionary.\n",
    "                    a = lang_dis[lang][gramtype][k].pop(key,0) +.5   #Gram count for particular gram in foreign language\n",
    "                    c = lang_dis['EN'][gramtype][k].get(key,0) +.5   #Gram count for particular gram in English\n",
    "                    \n",
    "                    if gramtype == \"words\" and \"NNP\" in key:\n",
    "                        continue\n",
    "                    \n",
    "                    # If it occurs more often than the lower bound, set value to the lowerbound of odds ratio.\n",
    "                    if a > lb:\n",
    "                        lang_dis[lang][gramtype][k][key] = math.log((a*d)/(b*c))  # Calculate the log-odds ratio \n",
    "                    \n",
    "    # Remove English from the language dictionary.\n",
    "    lang_dis[\"EN\"].clear()\n",
    "\n",
    "    return(lang_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lodds_ratio = construct_lodds_ratio_dict(\"trained_lang_dis_20_lang_ll10\", 5)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130249\n",
      "80360\n",
      "60487\n"
     ]
    }
   ],
   "source": [
    "training = pd.read_csv(\"python_data/training_final\")\n",
    "test = pd.read_csv(\"python_data/test_final\")\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as Detok\n",
    "detokenizer = Detok()\n",
    "word_gram_list = []\n",
    "char_gram_list = []\n",
    "struc_gram_list = []\n",
    "for lang in lodds_ratio.keys():\n",
    "    if lang == \"EN\":\n",
    "        continue\n",
    "    for gramtype in lodds_ratio[lang].keys():\n",
    "        for k in lodds_ratio[lang][gramtype].keys():\n",
    "            for key,v in lodds_ratio[lang][gramtype][k].items():\n",
    "                if v>math.log(6/5) or v<math.log(5/6):\n",
    "                    if gramtype == \"words\":\n",
    "                        word_gram_list.append(key)\n",
    "                    if gramtype == \"chars\":\n",
    "                        char_gram_list.append(key)\n",
    "                    if gramtype ==\"tags\":\n",
    "                        struc_gram_list.append(key)\n",
    "word_gram_list = set([detokenizer.detokenize(gram) for gram in set(word_gram_list)])\n",
    "struc_gram_list = set([detokenizer.detokenize(gram) for gram in set(struc_gram_list)])\n",
    "char_gram_list = set([''.join(gram) for gram in set(char_gram_list)])\n",
    "lodds_ratio.clear()\n",
    "gc.collect()\n",
    "print(len(word_gram_list))\n",
    "print(len(char_gram_list))\n",
    "print(len(struc_gram_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the transform for words, characters and structure.\n",
    "word_vectorizer = CountVectorizer(ngram_range=(1, 4), vocabulary = word_gram_list, lowercase=False)\n",
    "struc_vectorizer = CountVectorizer(ngram_range=(1, 4), vocabulary = struc_gram_list, lowercase=False)\n",
    "char_vectorizer = CountVectorizer(ngram_range=(1, 4), vocabulary = char_gram_list, analyzer=\"char\", lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_word_vector = word_vectorizer.transform(test[\"text_clean\"])\n",
    "test_char_vector = char_vectorizer.transform(test[\"text_clean\"])\n",
    "test_struc_vector = struc_vectorizer.transform(test[\"text_structure\"])\n",
    "sparse.save_npz(\"test_word_vector\",test_word_vector)\n",
    "sparse.save_npz(\"test_struc_vector\",test_struc_vector)\n",
    "sparse.save_npz(\"test_char_vector\",test_char_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification starts here. Do it for all gram types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying based on word-grams gives NB accuracy of 0.6967643409372912%\n",
      "Classifying based on word-grams with SVM with gradient descent gives accuracy of 72.24237218033151%\n",
      "Classifying based on character grams gives NB accuracy of 0.6490884795265821%\n",
      "Classifying based on character grams with SVM with gradient descent gives accuracy of 71.8208138462028%\n",
      "Classifying based on structure gives NB accuracy of 0.5802392542394451%\n",
      "Classifying based on structure with SVM with gradient descent gives accuracy of 60.45146511405937%\n"
     ]
    }
   ],
   "source": [
    "training = pd.read_csv(\"python_data/training_final\")\n",
    "test = pd.read_csv(\"python_data/test_final\")\n",
    "\n",
    "training_grams = sparse.load_npz(\"word_vector.npz\")\n",
    "test_grams = sparse.load_npz(\"test_word_vector.npz\")\n",
    "clf = MultinomialNB().fit(training_grams, training.native)\n",
    "predicted = clf.predict(test_grams)\n",
    "accuracy = 1-sum(predicted != test.native)/len(predicted)\n",
    "print(\"Classifying based on word-grams gives NB accuracy of {}%\".format(accuracy))\n",
    "clf = SGDClassifier(loss=\"hinge\",penalty=\"l2\",alpha=1e-4, random_state=42, max_iter=500, tol=None)\n",
    "clf.fit(training_grams, training.native)\n",
    "predicted_word = clf.predict(test_grams)\n",
    "accuracy = 1-sum(predicted_word != test.native)/len(predicted_word)\n",
    "print(\"Classifying based on word-grams with SVM with gradient descent gives accuracy of {}%\".format(accuracy*100))\n",
    "\n",
    "training_grams = sparse.load_npz(\"char_vector.npz\")\n",
    "test_grams = sparse.load_npz(\"test_char_vector.npz\")\n",
    "clf = MultinomialNB().fit(training_grams, training.native)\n",
    "predicted = clf.predict(test_grams)\n",
    "accuracy = 1-sum(predicted != test.native)/len(predicted)\n",
    "print(\"Classifying based on character grams gives NB accuracy of {}%\".format(accuracy))\n",
    "clf = SGDClassifier(loss=\"hinge\",penalty=\"l2\",alpha=1e-4, random_state=42, max_iter=500, tol=None)\n",
    "clf.fit(training_grams, training.native)\n",
    "predicted_char = clf.predict(test_grams)\n",
    "accuracy = 1-sum(predicted_char != test.native)/len(predicted_char)\n",
    "print(\"Classifying based on character grams with SVM with gradient descent gives accuracy of {}%\".format(accuracy*100))\n",
    "\n",
    "training_grams = sparse.load_npz(\"struc_vector.npz\")\n",
    "test_grams = sparse.load_npz(\"test_struc_vector.npz\")\n",
    "clf = MultinomialNB().fit(training_grams, training.native)\n",
    "predicted = clf.predict(test_grams)\n",
    "accuracy = 1-sum(predicted != test.native)/len(predicted)\n",
    "print(\"Classifying based on structure gives NB accuracy of {}%\".format(accuracy))\n",
    "clf = SGDClassifier(loss=\"hinge\",penalty=\"l2\",alpha=1e-4, random_state=42, max_iter=500, tol=None)\n",
    "clf.fit(training_grams, training.native)\n",
    "predicted_struc = clf.predict(test_grams)\n",
    "accuracy = 1-sum(predicted_struc != test.native)/len(predicted_struc)\n",
    "print(\"Classifying based on structure with SVM with gradient descent gives accuracy of {}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_struc = pd.DataFrame(predicted_struc, test.index)\n",
    "predicted_word = pd.DataFrame(predicted_word, test.index)\n",
    "predicted_char = pd.DataFrame(predicted_char, test.index)\n",
    "predicted_struc.columns = [\"prediction_struc\"]\n",
    "predicted_char.columns = [\"prediction_chars\"]\n",
    "predicted_word.columns = [\"prediction_words\"]\n",
    "\n",
    "# Merge the predictions and test dataframe.\n",
    "dfs = [test, predicted_struc, predicted_char, predicted_word]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right, left_index= True, right_index = True), dfs)\n",
    "df_final = df_final.drop(['text_original','text_structure'],1)\n",
    "df_final.to_csv(\"output_DTM_classifiers_TEST\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

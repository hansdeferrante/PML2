{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towards new features\n",
    "\n",
    "Unfortunately, parameter tuning for both Random Forests and SVM seems not to lead to large increases in classification performance. We might be able to increase, however, by extracting new features. Currently, the similarity score is calculated as in the paper. This similarity score has a number of oddities:\n",
    "- the presence of a k-gram in a model is weighted equally, regardless of k. Each k-gram leads to two (k-1)-grams. This means that k-grams with higher k are assigned lower weights.\n",
    "- The equal weighting does not take into account whether a word is somewhat specific to one of the language distributions. In the paper, they show for example that \"prove that\" is associated with Russians and \"refute\" with the Dutch. The weighting scheme does not take such correlations into account. We could take them into account by constructing a language distribution per language and calculating the idf-tf per word present.\n",
    "\n",
    "Even though it has problems, one should note that the highest classification performance in T1-language classification is typically reached by analyzing the n-grams directly, rather than similarity scores to n-gram models. Accuracies in the range of 80-90% have been reported for this task, which is conceptually more difficult than native-language classification as it concerns classification of the native language of the writer him/herself (e.g. Jarvis/Bestgen/Pepper, Gebre/Zampierie/Wittenburg). Some interesting results:\n",
    "- In Groningen, character n-grams in the range of 8-10 alone led to very high classification accuracies. We might want to see if we can use these.\n",
    "- Somewhat unexpectedly, an ensemble of learners applied to different types of n-grams has been reported to perform better than a single learner applied to the same n-grams by itself.\n",
    "\n",
    "## Load the necessary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import gc\n",
    "from functools import reduce\n",
    "from scipy import sparse\n",
    "from scipy.stats import norm\n",
    "from nltk import FreqDist, ngrams, sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, ParameterGrid, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import _pickle as pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        p = pickle.Pickler(output) \n",
    "        p.fast = True \n",
    "        p.dump(obj)\n",
    "        \n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training and validation data...\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the training data. Scramble the rows (sometimes this is important for training). We also downsample non-native\n",
    "# English s.t. we have a 1:1 balance. This is required for a fair comparison with the work by Al-Rfou.\n",
    "print(\"Loading the training and validation data...\")\n",
    "training = pd.read_csv(\"python_data/train\",sep=\"\\t\",error_bad_lines=False,encoding=\"utf-8\")\n",
    "training = training.sample(frac=1, random_state = 54021)\n",
    "training['native'] = np.where(training['native_lang']=='EN', \"native\", \"non-native\")\n",
    "training = pd.concat([training[training.native == \"non-native\"].sample(sum(training.native == \"native\"), random_state = 1810), training[training.native==\"native\"]])\n",
    "training = training.sample(frac=1, random_state = 1318910)\n",
    "training.native = training.native.astype('category')\n",
    "\n",
    "# Load the validation data. Again, downsample such that it is balanced.\n",
    "validation = pd.read_csv(\"python_data/development\",sep=\"\\t\",error_bad_lines=False,encoding=\"utf-8\")\n",
    "validation['native'] = np.where(validation['native_lang']=='EN', \"native\", \"non-native\")\n",
    "validation = pd.concat([validation[validation.native == \"non-native\"].sample(sum(validation.native == \"native\"), random_state = 1), validation[validation.native==\"native\"]])\n",
    "validation.native = validation.native.astype('category')\n",
    "print(\"Data loaded\")\n",
    "\n",
    "# Write data to CSV. We will compute features line by line as doing it in memory is impossible for 20 languages.\n",
    "training.to_csv(\"python_data/training_tfidf\")\n",
    "validation.to_csv(\"python_data/validation_tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating tf idf\n",
    "\n",
    "We want to construct a tf-idf library for all languages separately. Hence, first derive a language distribution for all 20 languages. We end with the English language distribution. The odds ratio is there 1, trivially, but we still include the lower bound such that the measure reflects the sample size of a and c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_keys(d):\n",
    "    return (0 if not isinstance(d, dict) else len(d) + sum(sum_keys(v) for v in d.values()))\n",
    "\n",
    "def pruned_language_distribution(n, m, lowerfreqlimit, training, LANGUAGES):\n",
    "    \"\"\"Calculate the word n grams distribution up to n, the character n gram distribution up to m.\n",
    "    @n: consider k-grams up to and including n for words, part of speech tags and word sizes.\n",
    "    @m: consider k-grams up to and including m for characters. We assume m >= n.\n",
    "    @lowerfreqlimit: number below which we consider words misspellings, odd words out or unique.\n",
    "    @training: training data to retrieve the language distribution from.\n",
    "    @LANGUAGES: languages based on which we classify.\n",
    "    \"\"\"\n",
    "    \n",
    "    language_dist = {}\n",
    "\n",
    "    for language in LANGUAGES:\n",
    "        language_dist[language] = {\"words\": dict(zip(range(1, n+1), [FreqDist() for i in range(1, n+1)])),\n",
    "                               \"tags\": dict(zip(range(1, n+1), [FreqDist() for i in range(1, n+1)])),\n",
    "                               \"chars\": dict(zip(range(1, m+1), [FreqDist() for i in range(1, m+1)])),\n",
    "                               \"w_sizes\": dict(zip(range(1, n+1), [FreqDist() for i in range(1, n+1)]))}\n",
    "        \n",
    "    # Iterate first over k. This is required as we need to know the full k-1 distributions to see if we should add a \n",
    "    # k-gram to the dictionary.\n",
    "    kmax = 0\n",
    "    for k in range(1, n+1):\n",
    "        print(\"Deriving the {}-gram distribution\".format(k))\n",
    "        for language, text, struc in training.itertuples(index=False):\n",
    "            \n",
    "            for sentence in sent_tokenize(text):\n",
    "                \n",
    "                # Get the necessary input structures for the ngrams-function. It is sentence for \"chars\".\n",
    "                token=word_tokenize(sentence) \n",
    "                wordlens = [len(word) for word in token]\n",
    "                \n",
    "                # Note, for any gram, there exist 2 subgrams of all but the first and all of the last element. Let us\n",
    "                # only update the dictionary if the total count of these subgrams exceeds the lower limit. This prevents\n",
    "                # an unnecessary combinatorial explosion.\n",
    "                for gram in ngrams(sentence,k):\n",
    "                    if k == 1: \n",
    "                        language_dist[language][\"chars\"][k][gram] += 1\n",
    "                    elif language_dist[language][\"chars\"][k-1].get(gram[1:],0)+language_dist[language][\"chars\"][k-1].get(gram[:-1],0) > 2*lowerfreqlimit:\n",
    "                        language_dist[language][\"chars\"][k][gram] += 1\n",
    "                        \n",
    "                for gram in ngrams(token,k):\n",
    "                    if k == 1:\n",
    "                        language_dist[language][\"words\"][k][gram] += 1\n",
    "                    elif language_dist[language][\"words\"][k-1].get(gram[1:],0)+language_dist[language][\"words\"][k-1].get(gram[:-1],0) > 2*lowerfreqlimit:\n",
    "                        language_dist[language][\"words\"][k][gram] += 1\n",
    "                        \n",
    "                for gram in ngrams(wordlens,k):\n",
    "                    if k == 1:\n",
    "                        language_dist[language][\"w_sizes\"][k][gram] += 1\n",
    "                    elif language_dist[language][\"w_sizes\"][k-1].get(gram[1:],0)+language_dist[language][\"w_sizes\"][k-1].get(gram[:-1],0) > 2*lowerfreqlimit:\n",
    "                        language_dist[language][\"w_sizes\"][k][gram] += 1\n",
    "                        \n",
    "            # Now for the tokenized structures (tags)\n",
    "            for sentence in sent_tokenize(struc):\n",
    "                token=word_tokenize(sentence)\n",
    "                for gram in ngrams(token,k):\n",
    "                    if k == 1:\n",
    "                        language_dist[language][\"tags\"][k][gram] += 1\n",
    "                    elif language_dist[language][\"tags\"][k-1].get(gram[1:],0)+language_dist[language][\"tags\"][k-1].get(gram[:-1],0) > 2*lowerfreqlimit:\n",
    "                        language_dist[language][\"tags\"][k][gram] += 1\n",
    "                        \n",
    "    # Also construct it for higher order k-grams for characters.\n",
    "    for k in range(n+1, m+1):\n",
    "        print(\"Deriving the {}-gram distribution for characters\".format(k))\n",
    "        for language, tokenized_sents, tokenized_struc in training.itertuples(index=False):\n",
    "            for sentence in tokenized_sents:\n",
    "                for gram in ngrams(sentence,k):\n",
    "                    if language_dist[language][\"chars\"][k-1].get(gram[1:],0)+language_dist[language][\"chars\"][k-1].get(gram[:-1],0) > 2*lowerfreqlimit:\n",
    "                        language_dist[language][\"chars\"][k][gram] += 1\n",
    "                           \n",
    "    return language_dist\n",
    "\n",
    "def construct_lodds_ratio_dict(fname, lb):\n",
    "    \"\"\" \n",
    "    In this function, we want to compute the odds ratio for each of the n-grams, and return a dictionary with these values.\n",
    "    For each non-English language, we will add a pseudocount of .5 to prevent divisions by 0. We return an approximate lower\n",
    "    bound at the alpha confidence level.\n",
    "    @fname: File to load the language distribution from\n",
    "    @alpha: level of alpha of lower bound. \n",
    "    \"\"\"\n",
    "    \n",
    "    lang_dis = load_object(fname)\n",
    "    \n",
    "    n = len(lang_dis['EN']['words'])\n",
    "    m = len(lang_dis['EN']['chars'])\n",
    "    \n",
    "    for lang in lang_dis.keys():\n",
    "        if lang == 'EN':\n",
    "            continue\n",
    "        for gramtype in lang_dis[lang].keys():  \n",
    "            for k in lang_dis[lang][gramtype].keys():\n",
    "                b = sum(lang_dis[lang][gramtype][k].values()) + .5   #Total grams in foreign language\n",
    "                d = sum(lang_dis['EN'][gramtype][k].values()) + .5   #Total grams in English\n",
    "                for key in list(lang_dis[lang][gramtype][k].keys()):\n",
    "                    \n",
    "                    # Obtain the value by pop, i.e. delete key from dictionary.\n",
    "                    a = lang_dis[lang][gramtype][k].pop(key,0) +.5   #Gram count for particular gram in foreign language\n",
    "                    c = lang_dis['EN'][gramtype][k].get(key,0) +.5   #Gram count for particular gram in English\n",
    "                    \n",
    "                    if gramtype == \"words\" and \"NNP\" in key:\n",
    "                        continue\n",
    "                    \n",
    "                    # If it occurs more often than the lower bound, set value to the lowerbound of odds ratio.\n",
    "                    if a > lb:\n",
    "                        lang_dis[lang][gramtype][k][key] = math.log((a*d)/(b*c))  # Calculate the log-odds ratio \n",
    "                    \n",
    "    # Remove English from the language dictionary.\n",
    "    lang_dis[\"EN\"].clear()\n",
    "\n",
    "    return(lang_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to construct a language distribution for different languages. Let us not do this by downsampling to the minimum number, but rather take the same training data as previously. The log-odds ratio takes into account imbalance in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Derive the language distribution from the training data.\n",
    "print(\"Deriving the language distribution from training data...\")\n",
    "start = time.time()\n",
    "lang_dis = pruned_language_distribution(4,4,10,training[['native_lang','text_clean','text_structure']], training.native_lang.unique())\n",
    "end = time.time()\n",
    "print(\"Language distribution constructed in {} seconds\".format(end-start))\n",
    "\n",
    "# Save it and clear it to save memory.\n",
    "save_object(lang_dis,\"trained_lang_dis_20_lang_ll10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can let our vocabulary as to which terms we want to analyze be guided by the odds ratio. This ratio is defined as $\\frac{(a/b)}{(c/d)}$. Since the count of a particular n-gram is negligible in comparison with the total number of n-grams, we can approximate b and d by the total number of n-grams in the foreign and English language distribution, respectively. We have explored using an asymptotic lower and upper bound on the odds ratio to select terms for the vocabulary used for the tokenizer. However, this has resulted in classification performance just short of 70%, which is not very good in comparison with the aggregate score. Therefore, let us be less conservative in selecting terms and allow for a bigger document-term matrix based on which we classify. To keep things somewhat robust, we put a lower bound on the gram count of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lodds_ratio = construct_lodds_ratio_dict(\"trained_lang_dis_20_lang_ll10\", 5)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"python_data/training_tfidf\")\n",
    "validation = pd.read_csv(\"python_data/validation_tfidf\")\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as Detok\n",
    "detokenizer = Detok()\n",
    "word_gram_list = []\n",
    "char_gram_list = []\n",
    "struc_gram_list = []\n",
    "for lang in lodds_ratio.keys():\n",
    "    if lang == \"EN\":\n",
    "        continue\n",
    "    for gramtype in lodds_ratio[lang].keys():\n",
    "        for k in lodds_ratio[lang][gramtype].keys():\n",
    "            for key,v in lodds_ratio[lang][gramtype][k].items():\n",
    "                if v>math.log(6/5) or v<math.log(5/6):\n",
    "                    if gramtype == \"words\":\n",
    "                        word_gram_list.append(key)\n",
    "                    if gramtype == \"chars\":\n",
    "                        char_gram_list.append(key)\n",
    "                    if gramtype ==\"tags\":\n",
    "                        struc_gram_list.append(key)\n",
    "word_gram_list = set([detokenizer.detokenize(gram) for gram in set(word_gram_list)])\n",
    "struc_gram_list = set([detokenizer.detokenize(gram) for gram in set(struc_gram_list)])\n",
    "char_gram_list = set([''.join(gram) for gram in set(char_gram_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130249\n",
      "80360\n",
      "60487\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "lodds_ratio.clear()\n",
    "gc.collect()\n",
    "print(len(word_gram_list))\n",
    "print(len(char_gram_list))\n",
    "print(len(struc_gram_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "training = pd.read_csv(\"python_data/training_tfidf\")\n",
    "validation = pd.read_csv(\"python_data/validation_tfidf\")\n",
    "\n",
    "# create the transform for words, characters and structure.\n",
    "word_vectorizer = CountVectorizer(ngram_range=(1, 4), vocabulary = word_gram_list, lowercase=False)\n",
    "struc_vectorizer = CountVectorizer(ngram_range=(1, 4), vocabulary = struc_gram_list, lowercase=False)\n",
    "char_vectorizer = CountVectorizer(ngram_range=(1, 4), vocabulary = char_gram_list, analyzer=\"char\", lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vector = word_vectorizer.transform(training[\"text_clean\"])\n",
    "struc_vector = struc_vectorizer.transform(training[\"text_structure\"])\n",
    "char_vector = char_vectorizer.transform(training[\"text_clean\"])\n",
    "sparse.save_npz(\"word_vector\",word_vector)\n",
    "sparse.save_npz(\"struc_vector\",struc_vector)\n",
    "sparse.save_npz(\"char_vector\",char_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_word_vector = word_vectorizer.transform(validation[\"text_clean\"])\n",
    "validation_char_vector = char_vectorizer.transform(validation[\"text_clean\"])\n",
    "validation_struc_vector = struc_vectorizer.transform(validation[\"text_structure\"])\n",
    "sparse.save_npz(\"val_word_vector\",validation_word_vector)\n",
    "sparse.save_npz(\"val_struc_vector\",validation_struc_vector)\n",
    "sparse.save_npz(\"val_char_vector\",validation_char_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start classification based on word and structure vectors. \n",
    "\n",
    "Here we restart Python and hope this prevents memory problems..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying based on word-grams gives NB accuracy of 0.6947756956274844%\n",
      "Classifying based on word-grams with SVM with gradient descent gives accuracy of 71.99192378068017%\n"
     ]
    }
   ],
   "source": [
    "training_grams = sparse.load_npz(\"word_vector.npz\")\n",
    "validation_grams = sparse.load_npz(\"val_word_vector.npz\")\n",
    "clf = MultinomialNB().fit(training_grams, training.native)\n",
    "predicted = clf.predict(validation_grams)\n",
    "accuracy = 1-sum(predicted != validation.native)/len(predicted)\n",
    "print(\"Classifying based on word-grams gives NB accuracy of {}%\".format(accuracy))\n",
    "clf = SGDClassifier(loss=\"hinge\",penalty=\"l2\",alpha=1e-4, random_state=42, max_iter=500, tol=None)\n",
    "clf.fit(training_grams, training.native)\n",
    "predicted_word = clf.predict(validation_grams)\n",
    "accuracy = 1-sum(predicted_word != validation.native)/len(predicted_word)\n",
    "print(\"Classifying based on word-grams with SVM with gradient descent gives accuracy of {}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying based on character grams gives NB accuracy of 0.6492838664899994%\n",
      "Classifying based on character grams with SVM with gradient descent gives accuracy of 71.55656508297054%\n"
     ]
    }
   ],
   "source": [
    "training_grams = sparse.load_npz(\"char_vector.npz\")\n",
    "validation_grams = sparse.load_npz(\"val_char_vector.npz\")\n",
    "clf = MultinomialNB().fit(training_grams, training.native)\n",
    "predicted = clf.predict(validation_grams)\n",
    "accuracy = 1-sum(predicted != validation.native)/len(predicted)\n",
    "print(\"Classifying based on character grams gives NB accuracy of {}%\".format(accuracy))\n",
    "clf = SGDClassifier(loss=\"hinge\",penalty=\"l2\",alpha=1e-4, random_state=42, max_iter=500, tol=None)\n",
    "clf.fit(training_grams, training.native)\n",
    "predicted_char = clf.predict(validation_grams)\n",
    "accuracy = 1-sum(predicted_char != validation.native)/len(predicted_char)\n",
    "print(\"Classifying based on character grams with SVM with gradient descent gives accuracy of {}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying based on structure gives NB accuracy of 0.5784276610511705%\n",
      "Classifying based on structure with SVM with gradient descent gives accuracy of 60.4012871474541%\n"
     ]
    }
   ],
   "source": [
    "training_grams = sparse.load_npz(\"struc_vector.npz\")\n",
    "validation_grams = sparse.load_npz(\"val_struc_vector.npz\")\n",
    "clf = MultinomialNB().fit(training_grams, training.native)\n",
    "predicted = clf.predict(validation_grams)\n",
    "accuracy = 1-sum(predicted != validation.native)/len(predicted)\n",
    "print(\"Classifying based on structure gives NB accuracy of {}%\".format(accuracy))\n",
    "clf = SGDClassifier(loss=\"hinge\",penalty=\"l2\",alpha=1e-4, random_state=42, max_iter=500, tol=None)\n",
    "clf.fit(training_grams, training.native)\n",
    "predicted_struc = clf.predict(validation_grams)\n",
    "accuracy = 1-sum(predicted_struc != validation.native)/len(predicted_struc)\n",
    "print(\"Classifying based on structure with SVM with gradient descent gives accuracy of {}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, SVM with some regularization works better than multivariate Naive Bayes. Let us spit out all predictions to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_struc = pd.DataFrame(predicted_struc, validation.index)\n",
    "predicted_word = pd.DataFrame(predicted_word, validation.index)\n",
    "predicted_char = pd.DataFrame(predicted_char, validation.index)\n",
    "predicted_struc.columns = [\"prediction_struc\"]\n",
    "predicted_char.columns = [\"prediction_chars\"]\n",
    "predicted_word.columns = [\"prediction_words\"]\n",
    "\n",
    "# Merge the predictions and validation dataframe.\n",
    "dfs = [validation, predicted_struc, predicted_char, predicted_word]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right, left_index= True, right_index = True), dfs)\n",
    "df_final = df_final.drop(['text_original','text_structure'],1)\n",
    "df_final.to_csv(\"output_DTM_classifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, inspection of df_final shows that the classifiers frequently disagree. It would be interesting to see what the majority vote would be. Let us postpone such an analysis to R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>native_lang</th>\n",
       "      <th>level_english</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>native</th>\n",
       "      <th>prediction_struc</th>\n",
       "      <th>prediction_chars</th>\n",
       "      <th>prediction_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23905</th>\n",
       "      <td>DE</td>\n",
       "      <td>3</td>\n",
       "      <td>NNP. your question: \"you NNP picked a bad day ...</td>\n",
       "      <td>non-native</td>\n",
       "      <td>native</td>\n",
       "      <td>non-native</td>\n",
       "      <td>non-native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>FR</td>\n",
       "      <td>5</td>\n",
       "      <td>There is also a similar discussion, (caused by...</td>\n",
       "      <td>non-native</td>\n",
       "      <td>native</td>\n",
       "      <td>non-native</td>\n",
       "      <td>non-native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42283</th>\n",
       "      <td>NL</td>\n",
       "      <td>4</td>\n",
       "      <td>It may be co-funded by an JJ network, but the ...</td>\n",
       "      <td>non-native</td>\n",
       "      <td>native</td>\n",
       "      <td>non-native</td>\n",
       "      <td>native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23101</th>\n",
       "      <td>PT</td>\n",
       "      <td>3</td>\n",
       "      <td>It could be worse! I actually refute the crap ...</td>\n",
       "      <td>non-native</td>\n",
       "      <td>native</td>\n",
       "      <td>non-native</td>\n",
       "      <td>non-native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23884</th>\n",
       "      <td>DA</td>\n",
       "      <td>3</td>\n",
       "      <td>NNP was proposed for deletion. This page is an...</td>\n",
       "      <td>non-native</td>\n",
       "      <td>non-native</td>\n",
       "      <td>non-native</td>\n",
       "      <td>native</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      native_lang level_english  \\\n",
       "23905          DE             3   \n",
       "272            FR             5   \n",
       "42283          NL             4   \n",
       "23101          PT             3   \n",
       "23884          DA             3   \n",
       "\n",
       "                                              text_clean      native  \\\n",
       "23905  NNP. your question: \"you NNP picked a bad day ...  non-native   \n",
       "272    There is also a similar discussion, (caused by...  non-native   \n",
       "42283  It may be co-funded by an JJ network, but the ...  non-native   \n",
       "23101  It could be worse! I actually refute the crap ...  non-native   \n",
       "23884  NNP was proposed for deletion. This page is an...  non-native   \n",
       "\n",
       "      prediction_struc prediction_chars prediction_words  \n",
       "23905           native       non-native       non-native  \n",
       "272             native       non-native       non-native  \n",
       "42283           native       non-native           native  \n",
       "23101           native       non-native       non-native  \n",
       "23884       non-native       non-native           native  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Compute similarity scores against log-odds dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we tried to compute a similarity score analogous to the one in the replication based on all 20 languages and odds ratios. This turns out to work pretty badly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_similarity_score_sum(dis_ngramdic, gramlist):\n",
    "    \"\"\" This function computes the similarity scores for a comment based on the corresponding k-grams.\n",
    "    Note that the comment is already tokenized into sentences.\n",
    "    @dis_ngramdic: ngram dictionary as constructed by language_distribution for particular k.\n",
    "    @gramlist: list of kgrams\n",
    "    \"\"\"\n",
    "    score=0\n",
    "    if gramlist:\n",
    "        for gram in gramlist:\n",
    "            score += dis_ngramdic.get(gram,1)\n",
    "    return score\n",
    "\n",
    "colnames = None\n",
    "\n",
    "\n",
    "def compute_all_features(lang_dis, original_text, clean_text, structure_text):\n",
    "    \"\"\" This function compares the sentences and structure to each of the languages distributions. It returns\n",
    "    similarity scores to each language model. Also included are other features, such as the number of sentences\n",
    "    per text, etc.\n",
    "    @lang_dis: Language distribution of n-grams.\n",
    "    @clean_text: Text with proper nouns and demonyms substituted\n",
    "    @structure_text: PoS structure retrieved by SENNA.\n",
    "    \"\"\"\n",
    "    simscoredict=dict()\n",
    "    \n",
    "    # For each gramtype, first construct the list of which we can make n-grams.\n",
    "    words_ps = list(word_tokenize(clean_text))\n",
    "    struc_ps = list(word_tokenize(structure_text))\n",
    "    wordlens_ps = [len(word) for word in word_tokenize(original_text) if word.isalpha()]\n",
    "    \n",
    "    # Now we should construct k-gram lists for each k and return the score. Let us store all grams in \n",
    "    for gramtype in lang_dis[list(lang_dis.keys())[0]].keys():\n",
    "        \n",
    "        # Select appropriate data type.\n",
    "        if gramtype == \"tags\":\n",
    "            ps = struc_ps\n",
    "        elif gramtype ==\"words\":\n",
    "            ps = words_ps\n",
    "        elif gramtype == \"w_sizes\":\n",
    "            ps = wordlens_ps\n",
    "        elif gramtype == \"chars\":\n",
    "            ps = clean_text\n",
    "            \n",
    "        seq_len = len(ps) if len(ps) != 0 else 1\n",
    "        \n",
    "        # For each k, feed the ngrams function into the compute_similarity_score function. \n",
    "        for k in range(1,len(lang_dis[list(lang_dis.keys())[0]][gramtype])+1):\n",
    "            for lang in lang_dis.keys():\n",
    "                simscoredict[lang+'_'+gramtype+'_'+str(k)] = compute_similarity_score_sum(lang_dis[lang][gramtype][k], ngrams(ps,k))/seq_len\n",
    "    \n",
    "    # Set the other features they use in the paper.\n",
    "    simscoredict[\"num_sentences\"] = len(list(sent_tokenize(clean_text)))\n",
    "    simscoredict[\"num_words\"] = len(wordlens_ps)\n",
    "    simscoredict[\"avg_wordlength\"] = sum(wordlens_ps)/len(wordlens_ps)\n",
    "        \n",
    "    global colnames\n",
    "    if colnames == None:\n",
    "        colnames = list(simscoredict.keys())\n",
    "            \n",
    "    return simscoredict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "print(\"Starting computing features against each language distribution\")\n",
    "start=time.time()\n",
    "\n",
    "with open(\"python_data/training_tfidf\") as infile, open(\"python_data/training_with_features_tfidf\",\"w\") as outfile:\n",
    "    # Open csv reader and writer.\n",
    "    r =  csv.reader(infile); w = csv.writer(outfile); next(r)\n",
    "    header_written = False\n",
    "    for row in r:\n",
    "        features = compute_all_features(lodds_ratio,row[2],row[4],row[5])\n",
    "        if not header_written:\n",
    "            w.writerow(['','native_lang','native','level']+colnames)\n",
    "            header_written = True\n",
    "        w.writerow([row[0], row[1], row[3], row[6]]+ list(features))\n",
    "\n",
    "with open(\"python_data/validation_tfidf\") as infile, open(\"python_data/validation_with_features_tfidf\",\"w\") as outfile:\n",
    "    # Open csv reader and writer.\n",
    "    r =  csv.reader(infile); w = csv.writer(outfile); next(r)\n",
    "    header_written = False\n",
    "    for row in r:\n",
    "        features = compute_all_features(lodds_ratio,row[2],row[4],row[5])\n",
    "        if not header_written:\n",
    "            w.writerow(['','native_lang','native','level']+colnames)\n",
    "            header_written = True\n",
    "        w.writerow([row[0], row[1], row[3], row[6]]+ list(features))\n",
    "\n",
    "print(\"Features calculated in {} seconds\".format(time.time()-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
